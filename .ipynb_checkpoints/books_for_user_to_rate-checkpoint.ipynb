{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ IN AND TRANSFORM DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>goodreads_book_id</th>\n",
       "      <th>tag_id</th>\n",
       "      <th>count</th>\n",
       "      <th>best_book_id</th>\n",
       "      <th>work_id</th>\n",
       "      <th>books_count</th>\n",
       "      <th>...</th>\n",
       "      <th>original_publication_year</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>work_ratings_count</th>\n",
       "      <th>work_text_reviews_count</th>\n",
       "      <th>ratings_1</th>\n",
       "      <th>ratings_2</th>\n",
       "      <th>ratings_3</th>\n",
       "      <th>ratings_4</th>\n",
       "      <th>ratings_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9976.000000</td>\n",
       "      <td>9976.000000</td>\n",
       "      <td>9976.000000</td>\n",
       "      <td>9976.000000</td>\n",
       "      <td>9.976000e+03</td>\n",
       "      <td>9976.000000</td>\n",
       "      <td>9976.000000</td>\n",
       "      <td>9.976000e+03</td>\n",
       "      <td>9.976000e+03</td>\n",
       "      <td>9976.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9955.000000</td>\n",
       "      <td>9976.000000</td>\n",
       "      <td>9.976000e+03</td>\n",
       "      <td>9.976000e+03</td>\n",
       "      <td>9976.000000</td>\n",
       "      <td>9976.000000</td>\n",
       "      <td>9976.000000</td>\n",
       "      <td>9976.000000</td>\n",
       "      <td>9.976000e+03</td>\n",
       "      <td>9.976000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4987.500000</td>\n",
       "      <td>6731.231355</td>\n",
       "      <td>4998.718625</td>\n",
       "      <td>3.883019</td>\n",
       "      <td>5.261925e+06</td>\n",
       "      <td>18469.374198</td>\n",
       "      <td>751.103749</td>\n",
       "      <td>5.468939e+06</td>\n",
       "      <td>8.642673e+06</td>\n",
       "      <td>75.821271</td>\n",
       "      <td>...</td>\n",
       "      <td>1981.950276</td>\n",
       "      <td>4.001930</td>\n",
       "      <td>5.398192e+04</td>\n",
       "      <td>5.967176e+04</td>\n",
       "      <td>2917.448877</td>\n",
       "      <td>1345.305934</td>\n",
       "      <td>3111.690257</td>\n",
       "      <td>11478.874800</td>\n",
       "      <td>1.996658e+04</td>\n",
       "      <td>2.376932e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2879.967477</td>\n",
       "      <td>10177.014619</td>\n",
       "      <td>2887.358263</td>\n",
       "      <td>0.970982</td>\n",
       "      <td>7.573804e+06</td>\n",
       "      <td>6675.902734</td>\n",
       "      <td>1740.292414</td>\n",
       "      <td>7.826389e+06</td>\n",
       "      <td>1.174485e+07</td>\n",
       "      <td>170.656903</td>\n",
       "      <td>...</td>\n",
       "      <td>152.755935</td>\n",
       "      <td>0.254343</td>\n",
       "      <td>1.573247e+05</td>\n",
       "      <td>1.677524e+05</td>\n",
       "      <td>6114.623605</td>\n",
       "      <td>6642.021432</td>\n",
       "      <td>9721.680691</td>\n",
       "      <td>28547.752122</td>\n",
       "      <td>5.142984e+04</td>\n",
       "      <td>7.973730e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1540.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.700000e+01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1750.000000</td>\n",
       "      <td>2.470000</td>\n",
       "      <td>2.716000e+03</td>\n",
       "      <td>5.510000e+03</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>323.000000</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.540000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2493.750000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>2497.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.620050e+04</td>\n",
       "      <td>11305.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>4.776750e+04</td>\n",
       "      <td>1.009040e+06</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1990.000000</td>\n",
       "      <td>3.850000</td>\n",
       "      <td>1.357150e+04</td>\n",
       "      <td>1.544300e+04</td>\n",
       "      <td>695.750000</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>656.000000</td>\n",
       "      <td>3113.000000</td>\n",
       "      <td>5.408750e+03</td>\n",
       "      <td>5.327500e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4987.500000</td>\n",
       "      <td>1948.000000</td>\n",
       "      <td>4998.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.947275e+05</td>\n",
       "      <td>20939.000000</td>\n",
       "      <td>338.000000</td>\n",
       "      <td>4.240925e+05</td>\n",
       "      <td>2.721782e+06</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>4.020000</td>\n",
       "      <td>2.117050e+04</td>\n",
       "      <td>2.386850e+04</td>\n",
       "      <td>1402.500000</td>\n",
       "      <td>391.000000</td>\n",
       "      <td>1163.000000</td>\n",
       "      <td>4896.500000</td>\n",
       "      <td>8.274000e+03</td>\n",
       "      <td>8.837500e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7481.250000</td>\n",
       "      <td>8865.000000</td>\n",
       "      <td>7498.250000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.376833e+06</td>\n",
       "      <td>23471.000000</td>\n",
       "      <td>778.000000</td>\n",
       "      <td>9.635536e+06</td>\n",
       "      <td>1.451529e+07</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2011.000000</td>\n",
       "      <td>4.180000</td>\n",
       "      <td>4.108250e+04</td>\n",
       "      <td>4.596325e+04</td>\n",
       "      <td>2736.250000</td>\n",
       "      <td>886.000000</td>\n",
       "      <td>2354.500000</td>\n",
       "      <td>9298.250000</td>\n",
       "      <td>1.604700e+04</td>\n",
       "      <td>1.733225e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9975.000000</td>\n",
       "      <td>53331.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.328864e+07</td>\n",
       "      <td>30386.000000</td>\n",
       "      <td>47478.000000</td>\n",
       "      <td>3.553423e+07</td>\n",
       "      <td>5.639960e+07</td>\n",
       "      <td>3455.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>4.820000</td>\n",
       "      <td>4.780653e+06</td>\n",
       "      <td>4.942365e+06</td>\n",
       "      <td>155254.000000</td>\n",
       "      <td>456191.000000</td>\n",
       "      <td>436802.000000</td>\n",
       "      <td>793319.000000</td>\n",
       "      <td>1.481305e+06</td>\n",
       "      <td>3.011543e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0       user_id       book_id       rating  \\\n",
       "count  9976.000000   9976.000000   9976.000000  9976.000000   \n",
       "mean   4987.500000   6731.231355   4998.718625     3.883019   \n",
       "std    2879.967477  10177.014619   2887.358263     0.970982   \n",
       "min       0.000000      1.000000      1.000000     1.000000   \n",
       "25%    2493.750000    370.000000   2497.750000     3.000000   \n",
       "50%    4987.500000   1948.000000   4998.500000     4.000000   \n",
       "75%    7481.250000   8865.000000   7498.250000     5.000000   \n",
       "max    9975.000000  53331.000000  10000.000000     5.000000   \n",
       "\n",
       "       goodreads_book_id        tag_id         count  best_book_id  \\\n",
       "count       9.976000e+03   9976.000000   9976.000000  9.976000e+03   \n",
       "mean        5.261925e+06  18469.374198    751.103749  5.468939e+06   \n",
       "std         7.573804e+06   6675.902734   1740.292414  7.826389e+06   \n",
       "min         1.000000e+00   1540.000000      2.000000  1.000000e+00   \n",
       "25%         4.620050e+04  11305.000000    117.000000  4.776750e+04   \n",
       "50%         3.947275e+05  20939.000000    338.000000  4.240925e+05   \n",
       "75%         9.376833e+06  23471.000000    778.000000  9.635536e+06   \n",
       "max         3.328864e+07  30386.000000  47478.000000  3.553423e+07   \n",
       "\n",
       "            work_id  books_count  ...  original_publication_year  \\\n",
       "count  9.976000e+03  9976.000000  ...                9955.000000   \n",
       "mean   8.642673e+06    75.821271  ...                1981.950276   \n",
       "std    1.174485e+07   170.656903  ...                 152.755935   \n",
       "min    8.700000e+01     1.000000  ...               -1750.000000   \n",
       "25%    1.009040e+06    23.000000  ...                1990.000000   \n",
       "50%    2.721782e+06    40.000000  ...                2004.000000   \n",
       "75%    1.451529e+07    67.000000  ...                2011.000000   \n",
       "max    5.639960e+07  3455.000000  ...                2017.000000   \n",
       "\n",
       "       average_rating  ratings_count  work_ratings_count  \\\n",
       "count     9976.000000   9.976000e+03        9.976000e+03   \n",
       "mean         4.001930   5.398192e+04        5.967176e+04   \n",
       "std          0.254343   1.573247e+05        1.677524e+05   \n",
       "min          2.470000   2.716000e+03        5.510000e+03   \n",
       "25%          3.850000   1.357150e+04        1.544300e+04   \n",
       "50%          4.020000   2.117050e+04        2.386850e+04   \n",
       "75%          4.180000   4.108250e+04        4.596325e+04   \n",
       "max          4.820000   4.780653e+06        4.942365e+06   \n",
       "\n",
       "       work_text_reviews_count      ratings_1      ratings_2      ratings_3  \\\n",
       "count              9976.000000    9976.000000    9976.000000    9976.000000   \n",
       "mean               2917.448877    1345.305934    3111.690257   11478.874800   \n",
       "std                6114.623605    6642.021432    9721.680691   28547.752122   \n",
       "min                   3.000000      11.000000      30.000000     323.000000   \n",
       "25%                 695.750000     196.000000     656.000000    3113.000000   \n",
       "50%                1402.500000     391.000000    1163.000000    4896.500000   \n",
       "75%                2736.250000     886.000000    2354.500000    9298.250000   \n",
       "max              155254.000000  456191.000000  436802.000000  793319.000000   \n",
       "\n",
       "          ratings_4     ratings_5  \n",
       "count  9.976000e+03  9.976000e+03  \n",
       "mean   1.996658e+04  2.376932e+04  \n",
       "std    5.142984e+04  7.973730e+04  \n",
       "min    7.500000e+02  7.540000e+02  \n",
       "25%    5.408750e+03  5.327500e+03  \n",
       "50%    8.274000e+03  8.837500e+03  \n",
       "75%    1.604700e+04  1.733225e+04  \n",
       "max    1.481305e+06  3.011543e+06  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books = pd.read_csv('data\\explicit_ratings.csv')\n",
    "books = books.rename(columns = {'genre.x': 'genre_x', 'genre.y': 'genre_y', 'tag_name.x': 'tag_name_x',  'tag_name.y': 'tag_name_y'})\n",
    "books.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features in the original dataset: 32\n",
      "\n",
      "\n",
      "Index(['Unnamed: 0', 'user_id', 'book_id', 'rating', 'goodreads_book_id',\n",
      "       'tag_id', 'count', 'tag_name_x', 'genre_x', 'tag_name_y', 'genre_y',\n",
      "       'best_book_id', 'work_id', 'books_count', 'isbn', 'isbn13', 'authors',\n",
      "       'original_publication_year', 'original_title', 'title', 'language_code',\n",
      "       'average_rating', 'ratings_count', 'work_ratings_count',\n",
      "       'work_text_reviews_count', 'ratings_1', 'ratings_2', 'ratings_3',\n",
      "       'ratings_4', 'ratings_5', 'image_url', 'small_image_url'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "\n",
      "number of languages in the original dataset: 26\n",
      "\n",
      "\n",
      "['eng' 'en-US' 'en-CA' nan 'spa' 'en-GB' 'fre' 'nl' 'ara' 'por' 'ger'\n",
      " 'nor' 'jpn' 'en' 'vie' 'ind' 'pol' 'tur' 'dan' 'fil' 'ita' 'per' 'swe'\n",
      " 'rum' 'mul' 'rus']\n"
     ]
    }
   ],
   "source": [
    "print('number of features in the original dataset: ' + str(len(books.columns)))\n",
    "print('\\n')\n",
    "print(books.columns)\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "print('number of languages in the original dataset: ' + str(len(books['language_code'].unique())))\n",
    "print('\\n')\n",
    "print(books['language_code'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shit to drop\n",
    "feats_to_drop = ['tag_name_x', 'tag_name_y', 'genre_y', 'best_book_id', 'small_image_url']\n",
    "good_languages = ['eng', 'en-US', 'en-CA', 'en-GB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.drop(feats_to_drop, axis =1, inplace = True)\n",
    "books = books.loc[books['language_code'].isin(good_languages)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features in the original dataset: 27\n",
      "\n",
      "\n",
      "Index(['Unnamed: 0', 'user_id', 'book_id', 'rating', 'goodreads_book_id',\n",
      "       'tag_id', 'count', 'genre_x', 'work_id', 'books_count', 'isbn',\n",
      "       'isbn13', 'authors', 'original_publication_year', 'original_title',\n",
      "       'title', 'language_code', 'average_rating', 'ratings_count',\n",
      "       'work_ratings_count', 'work_text_reviews_count', 'ratings_1',\n",
      "       'ratings_2', 'ratings_3', 'ratings_4', 'ratings_5', 'image_url'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "\n",
      "number of languages in the original dataset: 4\n",
      "\n",
      "\n",
      "['eng' 'en-US' 'en-CA' 'en-GB']\n"
     ]
    }
   ],
   "source": [
    "#check after dropping \n",
    "print('number of features in the original dataset: ' + str(len(books.columns)))\n",
    "print('\\n')\n",
    "print(books.columns)\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "print('number of languages in the original dataset: ' + str(len(books['language_code'].unique())))\n",
    "print('\\n')\n",
    "print(books['language_code'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET UNIQUE GENRES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fantasy' 'historical' 'romance' 'literary-fiction' 'mystery' 'scifi'\n",
      " 'nonfiction' 'suspense' 'action' 'humour' 'paranormal' 'drama' 'horror'\n",
      " 'adult' 'philosophy' 'crime']\n"
     ]
    }
   ],
   "source": [
    "genre = books['genre_x'].unique()\n",
    "print(genre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPECIFY CLASS - GENRE RELATIONSHIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will change this after we talk to expert\n",
    "class1 = ['fantasy', 'mystery', 'scifi', 'literary-fiction']\n",
    "class2 = ['literary-fiction', 'action', 'fantasy']\n",
    "class3 = ['literary-fiction', 'action', 'fantasy']\n",
    "class4 = ['literary-fiction', 'action', 'fantasy']\n",
    "class5 = ['literary-fiction', 'action', 'fantasy']\n",
    "class6 = ['literary-fiction', 'action', 'fantasy']\n",
    "class7 = ['literary-fiction', 'action', 'fantasy']\n",
    "class8 = ['literary-fiction', 'action', 'fantasy']\n",
    "class9 = ['literary-fiction', 'action', 'fantasy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class1_books = books.loc[books['genre_x'].isin(class1)]\n",
    "# class2_books = books.loc[books['genre_x'].isin(class2)]\n",
    "# class3_books = books.loc[books['genre_x'].isin(class3)]\n",
    "# class4_books = books.loc[books['genre_x'].isin(class4)]\n",
    "# class5_books = books.loc[books['genre_x'].isin(class5)]\n",
    "# class6_books = books.loc[books['genre_x'].isin(class6)]\n",
    "# class7_books = books.loc[books['genre_x'].isin(class7)]\n",
    "# class8_books = books.loc[books['genre_x'].isin(class8)]\n",
    "# class9_books = books.loc[books['genre_x'].isin(class9)]\n",
    "class1_books = pd.DataFrame()\n",
    "class2_books = pd.DataFrame()\n",
    "class3_books = pd.DataFrame()\n",
    "class4_books = pd.DataFrame()\n",
    "class5_books = pd.DataFrame()\n",
    "class6_books = pd.DataFrame()\n",
    "class7_books = pd.DataFrame()\n",
    "class8_books = pd.DataFrame()\n",
    "class9_books = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in class1: \n",
    "    j = books.loc[books['genre_x'] == i].sort_values(['genre_x','ratings_count'], ascending=[False, False]).drop_duplicates(['book_id']).reset_index(drop=True)\n",
    "    j = j.head(5)\n",
    "    class1_books = class1_books.append(j, ignore_index = True)\n",
    "    \n",
    "for i in class2: \n",
    "    j = books.loc[books['genre_x'] == i].sort_values(['genre_x','ratings_count'], ascending=[False, False]).drop_duplicates(['book_id']).reset_index(drop=True)\n",
    "    j = j.head(5)\n",
    "    class2_books = class2_books.append(j, ignore_index = True)\n",
    "    \n",
    "for i in class3: \n",
    "    j = books.loc[books['genre_x'] == i].sort_values(['genre_x','ratings_count'], ascending=[False, False]).drop_duplicates(['book_id']).reset_index(drop=True)\n",
    "    j = j.head(5)\n",
    "    class3_books = class3_books.append(j, ignore_index = True)\n",
    "\n",
    "for i in class4: \n",
    "    j = books.loc[books['genre_x'] == i].sort_values(['genre_x','ratings_count'], ascending=[False, False]).drop_duplicates(['book_id']).reset_index(drop=True)\n",
    "    j = j.head(5)\n",
    "    class4_books = class4_books.append(j, ignore_index = True)\n",
    "    \n",
    "for i in class5: \n",
    "    j = books.loc[books['genre_x'] == i].sort_values(['genre_x','ratings_count'], ascending=[False, False]).drop_duplicates(['book_id']).reset_index(drop=True)\n",
    "    j = j.head(5)\n",
    "    class5_books = class5_books.append(j, ignore_index = True)\n",
    "    \n",
    "for i in class6: \n",
    "    j = books.loc[books['genre_x'] == i].sort_values(['genre_x','ratings_count'], ascending=[False, False]).drop_duplicates(['book_id']).reset_index(drop=True)\n",
    "    j = j.head(5)\n",
    "    class6_books = class6_books.append(j, ignore_index = True)\n",
    "    \n",
    "for i in class7: \n",
    "    j = books.loc[books['genre_x'] == i].sort_values(['genre_x','ratings_count'], ascending=[False, False]).drop_duplicates(['book_id']).reset_index(drop=True)\n",
    "    j = j.head(5)\n",
    "    class7_books = class7_books.append(j, ignore_index = True)\n",
    "\n",
    "for i in class8: \n",
    "    j = books.loc[books['genre_x'] == i].sort_values(['genre_x','ratings_count'], ascending=[False, False]).drop_duplicates(['book_id']).reset_index(drop=True)\n",
    "    j = j.head(5)\n",
    "    class8_books = class8_books.append(j, ignore_index = True)\n",
    "    \n",
    "for i in class9: \n",
    "    j = books.loc[books['genre_x'] == i].sort_values(['genre_x','ratings_count'], ascending=[False, False]).drop_duplicates(['book_id']).reset_index(drop=True)\n",
    "    j = j.head(5)\n",
    "    class9_books = class9_books.append(j, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "class1_books.to_csv('data/books_to_display/class1.csv')\n",
    "class2_books.to_csv('data/books_to_display/class2.csv')\n",
    "class3_books.to_csv('data/books_to_display/class3.csv')\n",
    "class4_books.to_csv('data/books_to_display/class4.csv')\n",
    "class5_books.to_csv('data/books_to_display/class5.csv')\n",
    "class6_books.to_csv('data/books_to_display/class6.csv')\n",
    "class7_books.to_csv('data/books_to_display/class7.csv')\n",
    "class8_books.to_csv('data/books_to_display/class8.csv')\n",
    "class9_books.to_csv('data/books_to_display/class9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
